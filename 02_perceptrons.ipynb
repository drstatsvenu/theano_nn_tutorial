{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptrons\n",
    "```\n",
    "----------------------------------------------------------------------\n",
    "Filename : 02_perceptrons.ipynb\n",
    "Date     : 15th March, 2017\n",
    "Author   : Jaidev Deshpande\n",
    "Purpose  : Introducing perceptrons and hinge loss.\n",
    "Libraries: Theano and its dependencies\n",
    "----------------------------------------------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from utils import draw_decision_boundary\n",
    "plt.style.use('ggplot')\n",
    "plt.rc('figure', figsize=(8, 6))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make some dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(12345)\n",
    "xx = rng.multivariate_normal([0.5, 0.5], [[0, 0.05], [0.05, 0]], size=(100,))\n",
    "yy = rng.multivariate_normal([-0.5, -0.5], [[0, 0.05], [0.05, 0]], size=(100,))\n",
    "X = np.r_[xx, yy]\n",
    "Y = np.ones((200,))\n",
    "Y[:100] = -1\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron Learning Rule:\n",
    "![](perceptron.png)\n",
    "* ### Inputs $X$, $y$, where $X$ is a matrix with each row representing a training sample\n",
    "* ### Weights $W$ is a column vector of weights\n",
    "* ### Bias $b$\n",
    "* ### Hypothesis $f = XW + b$\n",
    "* ### Prediction $t$: 1 if $f \\geq 0$ else 0\n",
    "* ### Learning:\n",
    "    1. If the prediction is correct, do nothing.\n",
    "    2. If the prediction is a false positive, subtract the training sample from the weights\n",
    "    3. If the prediction is a false negative, add the training sample to the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Perceptron2D(object):\n",
    "    \n",
    "    def __init__(self, weights=None, rng=None):\n",
    "        if rng is None:\n",
    "            rng = np.random.RandomState(123)\n",
    "        if weights is None:\n",
    "            weights = rng.rand(3,)\n",
    "        self.weights = weights.reshape(-1, 1)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        if x.shape[1] == 2:\n",
    "            x = np.c_[x, np.ones((x.shape[0],))]\n",
    "        activation = np.dot(x, self.weights).ravel()\n",
    "        activation[activation < 0] = -1\n",
    "        activation[activation >= 0] = 1\n",
    "        return activation\n",
    "    \n",
    "    def train(self, x, y, n_iter=50):\n",
    "        x = np.c_[x, np.ones((x.shape[0],))]\n",
    "        prediction = self.predict(x)\n",
    "        _iter = 0\n",
    "        while not np.all(prediction == y):\n",
    "            false_negatives = np.logical_and(prediction == -1, y == 1)\n",
    "            false_positives = np.logical_and(prediction == 1, y == -1)\n",
    "            self.weights += np.sum(x[false_negatives, :], axis=0).reshape(-1, 1)\n",
    "            self.weights -= np.sum(x[false_positives, :], axis=0).reshape(-1, 1)\n",
    "            _iter += 1\n",
    "            prediction = self.predict(x)\n",
    "            if _iter > n_iter:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perc = Perceptron2D(weights=np.array([[-1], [1], [0.5]]))\n",
    "prediction = perc.predict(X)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(Y, prediction)))\n",
    "draw_decision_boundary(perc.weights.ravel(), X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perc.train(X, Y)\n",
    "prediction = perc.predict(X)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(Y, prediction)))\n",
    "draw_decision_boundary(perc.weights.ravel(), X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem: Which loss function does the perceptron minimize?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Hinge Loss\n",
    "### Defining the _activation_ $f$ of the perceptron as above, and $L$ as the number of samples:\n",
    "### Hinge Loss $H(W) = \\sum_{i \\in L}{max\\{0, 1 - y_{i}f\\}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano import tensor as T\n",
    "from theano import shared, function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(12345)\n",
    "x = T.dmatrix('x')\n",
    "y = T.dmatrix('y')\n",
    "w = shared(rng.rand(2, 1), name=\"w\")\n",
    "b = shared(rng.rand(1,), name=\"b\")\n",
    "f = T.dot(x, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From defintion of Hinge loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hinge_loss = T.sum(T.max(T.concatenate((T.zeros((x.shape[0], 1)), - f * y),\n",
    "                                        axis=1), axis=1), axis=0) / x.shape[0]\n",
    "predict = function([x], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prediction(activation):\n",
    "    activation = activation.ravel()\n",
    "    y = np.ones(activation.shape)\n",
    "    y[activation < 0] = -1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "activation = predict(X)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(Y, get_prediction(activation))))\n",
    "draw_decision_boundary(w.get_value().ravel().tolist() + [b.get_value()], X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gw, gb = T.grad(hinge_loss, [w, b])\n",
    "get_loss = function([x, y], hinge_loss)\n",
    "train = function([x, y], hinge_loss, updates=[(w, w - gw), (b, b - gb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(11):\n",
    "    if get_loss(X, Y.reshape(-1, 1)) > 0:\n",
    "        print(train(X, Y.reshape(-1, 1)))\n",
    "activation = predict(X)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(Y, get_prediction(activation))))\n",
    "draw_decision_boundary(w.get_value().ravel().tolist() + [b.get_value()], X, Y)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
